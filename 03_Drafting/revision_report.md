"""General Knowledge"" Claim",Verdict,Evidence-Based Critique & Reasoning
"""Supervised batch correction improves biological signal preservation.""",Dangerous / Misleading,"Analysis: While intuitively appealing (telling the algorithm what is ""biology"" so it preserves it), supervised methods often induce a ""Hall of Mirrors."" They force the data to conform to the labels, creating artificial separation between classes.Evidence:• Exaggerated Significance: Two-step methods like ComBat, when used with covariates, induce correlation structures that violate independence assumptions in downstream testing. This leads to inflated false-positive rates (vanishingly small p-values) that are mathematical artifacts, not biological discoveries [1].• Circular Logic: In biomarker discovery, if the batch adjustment ""knows"" the outcome, it can imprint the outcome onto the features. Benchmarks show that while supervised methods (e.g., SMNN) claim to retain cell-type features better [2], they risk catastrophic overfitting where the model learns the correction artifact rather than the biology [1, 3]."
"""Deep Learning (DL) is state-of-the-art for genomic classification.""",Context-Dependent (Often False),"Analysis: This claim is often imported from computer vision. In genomics, specifically tabular gene expression data with N<1000, DL frequently fails to outperform simpler, regularized linear models due to the ""curse of dimensionality"" and lack of spatial invariance.Evidence:• The ""900-Sample"" Threshold: A study on stroke outcome prediction found that DL only began to outperform linear regression when sample sizes exceeded 900 patients. Below that, linear models were superior [4].• Tabular Data Failure: Extensive benchmarking reveals that for tabular data (like RNA-seq count matrices), DL models often underperform tree-based methods (XGBoost) or regularized regression (Elastic Net) [4, 5].• Drug Response: In drug sensitivity prediction, Elastic Net consistently outperformed complex neural networks, likely due to better handling of high-dimensional, sparse feature spaces [6, 7]."
"""Foundation Models (e.g., scGPT) solve batch effects via massive pre-training.""",False / Premature,"Analysis: The assumption that ""scaling laws"" apply to batch correction—that seeing enough batches allows a model to zero-shot generalize—is empirically unsupported. These models often engage in ""shortcut learning,"" encoding technical artifacts as primary features.Evidence:• Shortcut Learning: Histopathology foundation models trained on millions of images still encode strong ""hospital signatures"" (site-specific stain/scanner artifacts) in their embeddings. Classifiers trained on these embeddings can predict the hospital of origin with high accuracy, indicating they are ""cheating"" by recognizing the site rather than the pathology [7, 8, 4, 9].• Zero-Shot Failure: In single-cell benchmarks (scSSL-Bench), foundation models often underperformed traditional, explicit correction methods like Harmony or scVI in zero-shot batch mixing tasks [10, 4]."
"""Random cross-validation (CV) prevents overfitting.""",Insufficient,"Analysis: Standard K-fold CV prevents overfitting to samples, but not to batches. If a batch contains samples from both classes, the model can learn batch-specific correlations (e.g., ""Batch A has high actin levels"") that do not generalize.Evidence:• The ""Optimism Gap"": Benchmarks in drug response prediction show massive performance drops (often >20%) when moving from within-dataset CV to cross-dataset prediction [11, 12, 13].• Clinical Reality: In proteomics, within-sample CV was ""optimistic,"" while leave-one-site-out CV revealed the true, lower performance (approx. 10% drop), which is the only relevant metric for clinical deployment [14]."
"""Batch correction can be performed on single clinical samples.""",False (for standard methods),"Analysis: Standard methods (ComBat, limma) are ""cohort-dependent""—they calculate a mean and variance relative to the current batch. A single patient sample has no ""batch mean"" to calculate, or worse, its correction depends on who else is in the queue that day.Evidence:• Frozen/Reference Methods: Clinical deployment requires modified algorithms like ""Caris-ComBat-seq"" or ""ComBat-ref"" that utilize a fixed reference batch. These allow a single new sample to be corrected deterministically against a static ""gold standard"" distribution without re-analyzing the entire cohort [6, 15, 16, 17]."
"""Single-cell data is composed of discrete cell types (Islands).""",Artifactual Metaphor,"Analysis: ""General knowledge"" treats cells as discrete clusters (T-cells, B-cells). However, biological processes (differentiation, cell cycle) are continuous manifolds (""Continents""). Algorithms like MNN (Mutual Nearest Neighbors) that force alignment between discrete anchors can tear or distort these continuous topologies.Evidence:• Manifold Distortion: Aggressive dimensionality reduction (t-SNE/UMAP) and discrete clustering often fragment continuous biological trajectories into arbitrary ""islands"" [18, 19, 20].• Topological Correction: Newer methods (e.g., LEMUR) explicitly model the data as a continuous manifold to avoid the artifacts introduced by ""premature discretization"" during batch correction [21]."
"""Integration always increases statistical power.""",Double-Edged Sword,"Analysis: While increasing N theoretically improves power, the noise introduced by imperfect batch correction often outweighs the benefit of added samples. If the ""biological signal to batch noise"" ratio is low, integration can degrade performance.Evidence:• Signal Erasure: Aggressive integration to force batch mixing can ""over-correct,"" removing genuine biological heterogeneity (e.g., rare cell states present in only one batch) because the algorithm assumes it to be a batch effect [6].• Feature Selection: Feature selection on uncorrected data often yields batch markers. Feature selection on corrected data can yield artifacts if the correction was imperfect. The most robust approach is often an ensemble of classifiers trained within batches and then combined, rather than merging data first [22]."