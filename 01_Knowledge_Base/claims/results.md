# Claims and Evidence: Result

This file contains all **Result** claims with their supporting evidence.

---

## C_21: The proposed hybrid model achieved classification accuracy exceeding 95.9% and a weighted F1-score above 95.8% on the TCGA dataset

**Category**: Result  
**Context**: Dataset included over 6,000 patient samples covering 13 cancer types.

**Primary Quote**:
> "In the initial modeling stage using gene expression data from over 6,000 patient samples covering 13 cancer types (TCGA dataset), the proposed model achieved classification accuracy exceeding 95.9% and a weighted F1-score above 95.8%."


---


## C_22: External validation of the hybrid model on Alzheimer's and Type 2 Diabetes datasets confirmed its generalizability

**Category**: Result  
**Context**: Accuracies reached 96.28% and 97.43% respectively.

**Primary Quote**:
> "External validation using Alzheimer's (GSE174367) and Type 2 Diabetes (GSE81608) datasets confirmed the model's generalizability, with accuracy values reaching 96.28% and 97.43%, and weighted F1-scores of 96.26% and 97.41%, respectively."


---


## C_25: For gene expression data, Wasserstein distance and correlation metrics consistently outperform mutual information-based metrics

**Category**: Result  
**Context**: Demonstrated across multiple cluster structures (2-10 clusters) and validated on independent Alzheimer's and Type 2 Diabetes datasets.

**Primary Quote**:
> "Fig. 4 shows the results for a two-cluster structure, representing the simplest division of data. Even at this level, the Wasserstein (WST) and correlation metrics outperform mutual information-based metrics (EMI, JF) in terms of classification accuracy. Figs. 5-7 (three to five clusters) illustrate that the advantage of WST and correlation metrics remains consistent, with a slight improvement in performance as the number of clusters increases."


---


## C_38: SVA increases the biological accuracy and reproducibility of analyses in genome-wide expression studies

**Category**: Result  
**Context**: Achieves operating characteristics nearly equivalent to what one would obtain with no expression heterogeneity at all.

**Primary Quote**:
> "We show that SVA increases the biological accuracy and reproducibility of analyses in genome-wide expression studies."


---


## C_42: GMMchi robustly and reliably extracts bimodal patterns from both colorectal cancer cell line-derived microarray and tumor-derived RNA-Seq data

**Category**: Result  
**Context**: Confirmed previously reported gene expression correlates of well-characterized CRC phenotypes.

**Primary Quote**:
> "We confirm that GMMchi robustly and reliably extracts bimodal patterns from both colorectal cancer (CRC) cell line-derived microarray and tumor-derived RNA-Seq data and verify previously reported gene expression correlates of some well-characterized CRC phenotypes."


---


## C_43: GMMchi achieved 85% accuracy with a sample size of n=90 in simulated data, and exceeds 90% accuracy with a sample size of about 1000

**Category**: Result  
**Context**: Demonstrates accuracy in categorizing simulated distributions across varying sample sizes.

**Primary Quote**:
> "GMMchi performs well with a minimum sample size, n, of about 100 and continues to do well with increasing sample size, exceeding 90% accuracy with a sample size of about 1000."


---


## C_51: CycleMix can flexibly assign cells to any number of states and accurately distinguish cycling from non-cycling cells

**Category**: Result  
**Context**: Benchmarked on both gold-standard and silver-standard datasets across different single-cell RNA-seq technologies.

**Primary Quote**:
> "We present CycleMix, a novel scalable cell-cycle classification algorithm based on Gaussian Mixture modeling. Briefly, this approach uses a weighted average log-normalized expression to combine positive and negative gene markers to generate stage-specific scores which are binarized into discrete classifications by fitting a mixture of Gaussian distributions and using the BIC to select the optimal model (Figure 1). This enabled it to more accurately distinguish cycling vs. non-cycling cells than the most commonly used approaches, while maintaining a high degree of scalability."


---


## C_53: Benchmarking on high-throughput droplet-based scRNAseq datasets showed CycleMix accurately assigned over 90% of quiescent cells to a non-cycling phase

**Category**: Result  
**Context**: This was consistent with Seurat exhibiting much higher false-positive rates for S and G2M cell-type assignments.

**Primary Quote**:
> "However, only CycleMix accurately assigned more than >90% of quiescent cells to a non-cycling phase, whereas Seurat assigned 25%-50% of quiescent cells to S/G2M."


---


## C_56: PhenoGMM successfully quantifies changes in microbial community structure based on flow cytometry data

**Category**: Result  
**Context**: Evaluated using data sets from both synthetic and natural ecosystems.

**Primary Quote**:
> "The method successfully quantifies changes in microbial community structure based on flow cytometry data, which can be expressed in terms of cytometric diversity. We evaluate the performance of PhenoGMM using data sets from both synthetic and natural ecosystems"


---


## C_60: In synthetic microbial communities, PhenoGMM showed moderate to highly correlated alpha-diversity estimations

**Category**: Result  
**Context**: This indicates that PhenoGMM captures community structure rather than identity.

**Primary Quote**:
> "PhenoGMM resulted in moderate to highly correlated a-diversity estimations and showed a better correspondence to the predefined community compositions compared to PhenoGrid. Estimations were just above the significance level ( P =0.05) for the latter. The performance mainly depended on the sensitivity parameter q . Estimations resulted in higher correlations for PhenoGMM when q . 0, i.e., when more weight was given to more abundant strains. This means that PhenoGMM captured the structure rather than the identity of a microbial community."


---


## C_61: PhenoGMM successfully quantified the community structure of most natural freshwater microbial communities

**Category**: Result  
**Context**: Performance varied by ecosystem but was successful for most considered natural communities.

**Primary Quote**:
> "To summarize, PhenoGMM successfully quantified the community structure of most considered natural communities, but its ability depended on the ecosystem of study and its specific implementation."


---


## C_78: Random forest gene selection yields very small sets of genes while preserving predictive accuracy

**Category**: Result  
**Context**: Demonstrated using simulated and nine microarray datasets.

**Primary Quote**:
> "Our method returns very small sets of genes compared to alternative variable selection methods, while retaining predictive performance."


---


## C_87: Neural networks outperform state-of-the-art methods only for very large training set sizes in gene expression classification

**Category**: Result  
**Context**: For small training sets, transfer learning may strongly improve model performance.

**Primary Quote**:
> "We show that neural networks outperform the state-of-the-art methods only for very large training set size. For a small training set, we show that transfer learning is possible and may strongly improve the model performance in some cases."


---


## C_92: fRMA is comparable to RMA when data are analyzed as a single batch and outperforms RMA when analyzing multiple batches

**Category**: Result  
**Context**: Demonstrates that reference-based approaches maintain quality while enabling flexibility.

**Primary Quote**:
> "We find that fRMA is comparable to RMA when the data are analyzed as a single batch and outperforms RMA when analyzing multiple batches."


---


## C_98: No single normalization method performs best across all proteomics datasets

**Category**: Result  
**Context**: Systematic evaluation across multiple datasets (UPS1, CPTAC, SGSD) reveals context-dependent performance, though Vsn performed consistently well overall.

**Primary Quote**:
> "While no single method gave the highest AUC in every two-group comparison, the Vsn normalization performed consistently well, giving high AUCs throughout all data sets."


---


